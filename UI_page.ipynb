{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuLEGLYxALt7f8Ik4rpVCo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinsaimajji/voice1/blob/main/UI_page.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poCy1odMMGwA",
        "outputId": "6a915d48-627a-413a-f8b8-d6b4bda72f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'voice1' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nitinsaimajji/voice1.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "MzOSiPewMH4T"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHu3eKc-NsKJ",
        "outputId": "6cf1dbc5-b6e2-4052-e81c-4c7d89e0f9e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python_speech_features in /usr/local/lib/python3.10/dist-packages (0.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo_aYfGiNJFH",
        "outputId": "d6deacdb-9d13-48ed-b03d-c93592d52fce"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## App"
      ],
      "metadata": {
        "id": "D0uQ-4zQMaX-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from pydub import AudioSegment\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pydub import AudioSegment\n",
        "from python_speech_features import mfcc\n",
        "from time import time\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def extract_features(file_name):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name) \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        \n",
        "        if mfccs.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - mfccs.shape[1]\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_pad_len]\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None \n",
        "     \n",
        "    return mfccs\n",
        "    \n",
        "\n",
        "fulldatasetpath = '/content/voice1/dataset1'\n",
        "\n",
        "df = pd.read_csv('/content/voice1/wav_check.csv')\n",
        "\n",
        "\n",
        "features = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    \n",
        "    file_name = os.path.join(os.path.abspath(fulldatasetpath)+'/',str(row[\"filename\"]))\n",
        "    \n",
        "    class_label = row[\"gender\"]\n",
        "    data = extract_features(file_name)\n",
        "    \n",
        "    features.append([data, class_label])\n",
        "\n",
        "\n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "\n",
        "\n",
        "\n",
        "model = load_model('model.h5')\n",
        "num_rows = 40\n",
        "num_columns = 174\n",
        "num_channels = 1\n",
        "\n",
        "max_pad_len = 174\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_uploaded_file(file):\n",
        "    with open(file.name, \"wb\") as f:\n",
        "        f.write(file.getbuffer())\n",
        "    return file.name\n",
        "\n",
        "def print_prediction(file_name):\n",
        "    prediction_feature = extract_features(file_name) \n",
        "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
        "\n",
        "    predicted_vector = model.predict(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(np.argmax(predicted_vector, axis=-1)) \n",
        "    st.subheader(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = predicted_vector\n",
        "    for i in range(len(predicted_proba_vector[0])): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        st.write(category[0], \"\\t\\t : \",round(predicted_proba_vector[0][i]*100,2),\"%\")\n",
        "\n",
        "def main():\n",
        "    st.title(\"Gender Prediction App\")\n",
        "    file = st.file_uploader(\"Upload an MP3 file\", type=[\"mp3\"])\n",
        "    if file:\n",
        "       \n",
        "        file_path = save_uploaded_file(file)\n",
        "\n",
        "        audio_bytes =file.read()\n",
        "        st.audio(audio_bytes, format='audio/wav')\n",
        "        path='/content/'+str(file_path)\n",
        "        input_file = path\n",
        "        output_file = \"/content/streamcheck.wav\"\n",
        "\n",
        "        audio = AudioSegment.from_file(input_file, format=\"mp3\")\n",
        "        audio.export(output_file, format=\"wav\")\n",
        "\n",
        "        filename = '/content/streamcheck.wav' \n",
        "        print_prediction(filename) \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEeclA4IMbCD",
        "outputId": "3bf7b804-9302-47bf-955a-97cac3beab86"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6VbAZuMN21",
        "outputId": "82cea012-9053-47d4-c046-acd18f52e555"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.338s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qOZ35LMTTQ",
        "outputId": "614253ba-6673-4c6c-8dd9-ec762220e148"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.245.149.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWzW_fVOMW1k",
        "outputId": "948b082a-6cb0-4460-f370-7efe71af9b69"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.698s\n",
            "your url is: https://nasty-dogs-hide.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WCzOVHUM4dD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}