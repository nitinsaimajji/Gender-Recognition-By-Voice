{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAjyXcz0JxcuMVflsXHDdE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitinsaimajji/voice1/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poCy1odMMGwA",
        "outputId": "13f96e6a-a3d0-4828-a4a5-66988f392001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'voice1'...\n",
            "remote: Enumerating objects: 952, done.\u001b[K\n",
            "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
            "remote: Compressing objects: 100% (186/186), done.\u001b[K\n",
            "remote: Total 952 (delta 138), reused 197 (delta 91), pack-reused 672\u001b[K\n",
            "Receiving objects: 100% (952/952), 168.24 MiB | 23.94 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "Updating files: 100% (1222/1222), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nitinsaimajji/voice1.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit"
      ],
      "metadata": {
        "id": "MzOSiPewMH4T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python_speech_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHu3eKc-NsKJ",
        "outputId": "14a0bccc-f4f1-47d5-ea61-428796b2ada0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python_speech_features\n",
            "  Downloading python_speech_features-0.6.tar.gz (5.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python_speech_features\n",
            "  Building wheel for python_speech_features (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python_speech_features: filename=python_speech_features-0.6-py3-none-any.whl size=5870 sha256=d2d158372d6f8744072627915595fed57d5fcdb98a38335e762a8017f2e74af3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/9e/68/30bad9462b3926c29e315df16b562216d12bdc215f4d240294\n",
            "Successfully built python_speech_features\n",
            "Installing collected packages: python_speech_features\n",
            "Successfully installed python_speech_features-0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo_aYfGiNJFH",
        "outputId": "411a6164-4881-4185-a993-ee24570caa62"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## App"
      ],
      "metadata": {
        "id": "D0uQ-4zQMaX-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from pydub import AudioSegment\n",
        "from tensorflow.keras.models import load_model\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pydub import AudioSegment\n",
        "from python_speech_features import mfcc\n",
        "from time import time\n",
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "import os\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def extract_features(file_name):\n",
        "    try:\n",
        "        audio, sample_rate = librosa.load(file_name) \n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "        \n",
        "        if mfccs.shape[1] < max_pad_len:\n",
        "            pad_width = max_pad_len - mfccs.shape[1]\n",
        "            mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "        else:\n",
        "            mfccs = mfccs[:, :max_pad_len]\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(\"Error encountered while parsing file: \", file_name)\n",
        "        return None \n",
        "     \n",
        "    return mfccs\n",
        "    \n",
        "\n",
        "fulldatasetpath = '/content/voice1/dataset1'\n",
        "\n",
        "df = pd.read_csv('/content/voice1/wav_check.csv')\n",
        "\n",
        "\n",
        "features = []\n",
        "\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    \n",
        "    file_name = os.path.join(os.path.abspath(fulldatasetpath)+'/',str(row[\"filename\"]))\n",
        "    \n",
        "    class_label = row[\"gender\"]\n",
        "    data = extract_features(file_name)\n",
        "    \n",
        "    features.append([data, class_label])\n",
        "\n",
        "\n",
        "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
        "\n",
        "print('Finished feature extraction from ', len(featuresdf), ' files') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = np.array(featuresdf.feature.tolist())\n",
        "y = np.array(featuresdf.class_label.tolist())\n",
        "le = LabelEncoder()\n",
        "yy = to_categorical(le.fit_transform(y)) \n",
        "\n",
        "\n",
        "\n",
        "model = load_model('model.h5')\n",
        "num_rows = 40\n",
        "num_columns = 174\n",
        "num_channels = 1\n",
        "\n",
        "max_pad_len = 174\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def save_uploaded_file(file):\n",
        "    with open(file.name, \"wb\") as f:\n",
        "        f.write(file.getbuffer())\n",
        "    return file.name\n",
        "\n",
        "def print_prediction(file_name):\n",
        "    prediction_feature = extract_features(file_name) \n",
        "    prediction_feature = prediction_feature.reshape(1, num_rows, num_columns, num_channels)\n",
        "\n",
        "    predicted_vector = model.predict(prediction_feature)\n",
        "    predicted_class = le.inverse_transform(np.argmax(predicted_vector, axis=-1)) \n",
        "    st.write(\"The predicted class is:\", predicted_class[0], '\\n') \n",
        "\n",
        "    predicted_proba_vector = predicted_vector\n",
        "    for i in range(len(predicted_proba_vector[0])): \n",
        "        category = le.inverse_transform(np.array([i]))\n",
        "        st.write(category[0], \"\\t\\t : \",round(predicted_proba_vector[0][i]*100,2),\"%\")\n",
        "\n",
        "def main():\n",
        "    st.title(\"Gender Prediction App\")\n",
        "    file = st.file_uploader(\"Upload an MP3 file\", type=[\"mp3\"])\n",
        "    if file:\n",
        "       \n",
        "        file_path = save_uploaded_file(file)\n",
        "\n",
        "        \n",
        "        path='/content/'+str(file_path)\n",
        "        input_file = path\n",
        "        output_file = \"/content/streamcheck.wav\"\n",
        "\n",
        "        audio = AudioSegment.from_file(input_file, format=\"mp3\")\n",
        "        audio.export(output_file, format=\"wav\")\n",
        "\n",
        "        filename = '/content/streamcheck.wav' \n",
        "        print_prediction(filename) \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEeclA4IMbCD",
        "outputId": "80f98f9e-f830-4d4a-ca89-c5402a5f4c8a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc6VbAZuMN21",
        "outputId": "3b44f9bd-9bb5-4130-fd60-613c51bdefa9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35mcli\u001b[0m npm v9.6.7 does not support Node.js v14.16.0. This version of npm supports the following node versions: `^14.17.0 || ^16.13.0 || >=18.0.0`. You can find the latest version at https://nodejs.org/.\n",
            "\u001b[K\u001b[?25h\n",
            "up to date in 414ms\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qOZ35LMTTQ",
        "outputId": "599ba992-c6c4-4eea-cceb-031ece30a451"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.125.172.248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWzW_fVOMW1k",
        "outputId": "444e293e-28b2-41c3-e9d5-78fc371ea9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35mcli\u001b[0m npm v9.6.7 does not support Node.js v14.16.0. This version of npm supports the following node versions: `^14.17.0 || ^16.13.0 || >=18.0.0`. You can find the latest version at https://nodejs.org/.\n",
            "\u001b[0myour url is: https://tall-feet-film.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WCzOVHUM4dD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}